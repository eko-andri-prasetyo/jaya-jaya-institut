# -*- coding: utf-8 -*-
"""notebook-institut.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l8cHBDRGhBrtOrRDFfg7hvaiw7JWq4UH

# Submission Akhir — Menyelesaikan Permasalahan Institusi Pendidikan (Jaya Jaya Institut)

Notebook ini menjalankan **end-to-end proses data science**:
- Business understanding
- Data understanding & EDA
- Preprocessing
- Modeling (multiclass classification)
- Evaluasi
- Export model untuk dipakai oleh Streamlit (`app.py`)
- Mempersiapkan database SQLite untuk Metabase (`dashboard/students.db`)

## 1) Business Understanding

**Masalah:** Jaya Jaya Institut menghadapi angka *dropout* yang cukup tinggi.  
**Tujuan:** membangun sistem prediksi untuk mendeteksi mahasiswa yang berpotensi `Dropout` sedini mungkin agar dapat diberi intervensi (bimbingan akademik/finansial).

**Target model:** memprediksi kolom `Status` (`Dropout`, `Enrolled`, `Graduate`).  
**Metrik utama:** Macro F1 (karena kelas tidak seimbang) + Accuracy sebagai metrik tambahan.
"""

import os
import json
import sqlite3
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score

import joblib

sns.set_theme()

# Load data
DATA_PATH = "data/data.csv"

# Dataset menggunakan separator ';'
df = pd.read_csv(DATA_PATH, sep=';')

print("Shape:", df.shape)
df.head()

# Basic checks
display(df.info())
display(df.describe(include='all').T.head(10))

print("\nMissing values (top 10):")
display(df.isna().sum().sort_values(ascending=False).head(10))

print("\nTarget distribution:")
display(df['Status'].value_counts())

"""## 2) EDA (Exploratory Data Analysis)

Kita akan melihat:
- Distribusi target `Status`
- Korelasi/perbandingan beberapa fitur penting terhadap target (contoh: Debtor, Scholarship, Admission grade, performa semester 1/2)

"""

# Distribusi target
plt.figure(figsize=(6,4))
df['Status'].value_counts().plot(kind='bar')
plt.title("Distribusi Target (Status)")
plt.xlabel("Status")
plt.ylabel("Jumlah")
plt.show()

# Contoh: Status vs Debtor / Scholarship holder
fig, ax = plt.subplots(1, 2, figsize=(12,4))

pd.crosstab(df['Debtor'], df['Status'], normalize='index').plot(kind='bar', stacked=True, ax=ax[0])
ax[0].set_title("Proporsi Status berdasarkan Debtor")
ax[0].set_xlabel("Debtor")
ax[0].set_ylabel("Proporsi")

pd.crosstab(df['Scholarship_holder'], df['Status'], normalize='index').plot(kind='bar', stacked=True, ax=ax[1])
ax[1].set_title("Proporsi Status berdasarkan Scholarship Holder")
ax[1].set_xlabel("Scholarship holder")
ax[1].set_ylabel("Proporsi")

plt.tight_layout()
plt.show()

# Admission grade per status
plt.figure(figsize=(8,4))
sns.boxplot(data=df, x='Status', y='Admission_grade')
plt.title("Admission grade per Status")
plt.show()

"""## 3) Modeling

Kita gunakan baseline yang stabil dan mudah dijelaskan:
- Pipeline: Imputer (median) → StandardScaler → Logistic Regression (multinomial)  
- `class_weight='balanced'` untuk mengurangi efek imbalance.

"""

TARGET = "Status"
X = df.drop(columns=[TARGET])
y = df[TARGET]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Train:", X_train.shape, "Test:", X_test.shape)

pipe = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler()),
    ("model", LogisticRegression(
        max_iter=3000,
        multi_class="multinomial",
        class_weight="balanced"
    ))
])

pipe.fit(X_train, y_train)

pred = pipe.predict(X_test)

acc = accuracy_score(y_test, pred)
f1m = f1_score(y_test, pred, average="macro")

print("Accuracy:", acc)
print("Macro F1 :", f1m)
print("\nClassification report:")
print(classification_report(y_test, pred, digits=4))

cm = confusion_matrix(y_test, pred, labels=pipe.named_steps["model"].classes_)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d',
            xticklabels=pipe.named_steps["model"].classes_,
            yticklabels=pipe.named_steps["model"].classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""## 4) Export Artifacts

- Simpan model ke `model/model.joblib`
- Simpan schema untuk Streamlit form ke `model/schema.json`
- Simpan metrik ke `model/metrics.json`

"""

from pathlib import Path

out_model_dir = Path("model")
out_model_dir.mkdir(exist_ok=True)

# Save model
joblib.dump(pipe, out_model_dir / "model.joblib")

# Save schema (fitur, range, default)
schema = {
    "target": TARGET,
    "classes": list(pipe.named_steps["model"].classes_),
    "features": []
}

for col in X.columns:
    s = df[col]
    info = {"name": col, "type": "numeric"}

    info["min"] = float(np.nanmin(s))
    info["max"] = float(np.nanmax(s))
    info["default"] = float(np.nanmedian(s))

    # mark int/float
    if np.all(np.isclose(s.dropna() % 1, 0)):
        info["subtype"] = "int"
    else:
        info["subtype"] = "float"

    schema["features"].append(info)

(out_model_dir / "schema.json").write_text(json.dumps(schema, indent=2), encoding="utf-8")

# Save metrics
metrics = {"accuracy": float(acc), "macro_f1": float(f1m)}
(out_model_dir / "metrics.json").write_text(json.dumps(metrics, indent=2), encoding="utf-8")

print("Saved:", out_model_dir / "model.joblib")
print("Saved:", out_model_dir / "schema.json")
print("Saved:", out_model_dir / "metrics.json")

"""## 5) Persiapan Database untuk Dashboard (Metabase)

Agar Metabase mudah mengakses data, kita buat SQLite DB: `dashboard/students.db` berisi tabel `students`.

"""

from pathlib import Path

db_dir = Path("dashboard")
db_dir.mkdir(exist_ok=True)
db_path = db_dir / "students.db"

if db_path.exists():
    db_path.unlink()

conn = sqlite3.connect(db_path)
df.to_sql("students", conn, index=False)
conn.close()

print("SQLite DB saved to:", db_path.resolve())

"""## 6) Conclusion & Action Items

**Kesimpulan:**  
- Model baseline multiclass sudah dapat memprediksi status mahasiswa dengan performa moderat (lihat metrik).  
- Untuk penggunaan nyata, fokuskan intervensi pada mahasiswa dengan probabilitas Dropout tinggi.

**Action items:**  
1. Implementasi *early warning system* dan konseling rutin untuk mahasiswa berisiko tinggi.  
2. Intervensi finansial untuk kelompok Debtor dan monitoring pembayaran.  
3. Program remedial untuk mahasiswa dengan performa semester awal rendah.  
4. Audit course yang dropout-nya tinggi dan perbaiki kurikulum/pengajaran.  
5. Monitoring berkala via dashboard (bulanan/semester) dengan target penurunan dropout.

"""